{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To best understand, imagine if we were to hardcode the weights the model will try, and lets say there are 1,000 possible weights.\\\n",
    "Theses weights could be just small increments, slowly bringing us to the \"local\" minimum, then slowly back away.\\\n",
    "It would look something like this.\\\n",
    "\\\n",
    "![hardcode](./img/grad_desc(0).png)\n",
    "\\\n",
    "If we had a network with 4 input nodes 5 hidden layer nodes and just 1 output node, that would create 25 connections, or 25 weights.\\\n",
    "With 25 connections between nodes and 1000 possible weights, that gives $10^{75}$ possible combinations.\\\n",
    "To put it short the worlds fastes computer is capable of 1.1 exaflops($10^{18}$ flops).\\\n",
    "If the worlds fasters computer where to run all these operations, it would take $8.6196151^{67}$ years,\\\n",
    "which is longer than the existance of the universe.\\\n",
    "\\\n",
    "Gradient Descent is an optimization algorithmn used to find the local minimum of a differentiable(cost), function.\\\n",
    "Or, it helps find the best parameters(coefficients) that the model needs operate at with the best loss.\\\n",
    "Remember, loss is normally a negative value that's not 0, and the closer to 0 the loss is, the lower the error is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Is A Gradient\n",
    "*\"A gradient measures how much the output of a function changes if you change the inputs a little bit.\"* — Lex Fridman (MIT)\\\n",
    "\\\n",
    "A gradient is the amount of change in the models predicted error with regard to the amount of change in the weights.\\\n",
    "Lets imagine a ball rolling down a hill to the bottom of a valley.\\\n",
    "\\\n",
    "![valley](./img/grad_desc(1).png)\n",
    "\\\n",
    "Notice how the size of the step x1 is much larger than the size of the step x4.\\\n",
    "We can see this also matches the slope of the valley in the map.\\\n",
    "Where the valley walls are steeper the balls travel distance is greater,\\\n",
    "but as the ball approaches the bottom the valley the slope decrease as the speed of the ball.\\\n",
    "There for the closer the ball is to the bottom of the valley the shorter the stride of the ball."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Gradient Descent \n",
    "The way gradient descent works is by finding the next position on the map by finding the steepest descent and compairing it to the current postition.\n",
    "This equation can help descripe what the gradient descent algorithm does.\n",
    "> #### $b=a-\\gamma\\Delta f(a)$\n",
    "$b$ is the balls next position on the map.\\\n",
    "$a$ is the current position of the ball.\\\n",
    "$\\gamma$ is a waiting factor, it will affect the size of the step.\\\n",
    "$\\Delta f(a)$ is a fuction that returns the direction of the steepest slope.\\\n",
    "\\\n",
    "What this tells us is the next position the ball will be in, which is direction of the steepest slope.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Size / Learning Rate\n",
    "The size of the gradients step towards the local minimum is determined by the *Learning Rate*.\\\n",
    "In order for the gradient descent to reach the local minimum, the learning rate can not be to high or to low.\\\n",
    "This illustration shows bacsic examples of higher and lower learning rates.\\\n",
    "\\\n",
    "![step](./img/grad_desc(2).png)\n",
    "\\\n",
    "If a learning rate is set higher, the model will adjust the weights in larger increments, moving towards the local minimum faster.\\\n",
    "Like in the ball example however, if the ball is rolling to fast it is likely to roll past the local minimum.\\\n",
    "Which isn't horrible, the weights would just be adjusted again to \"roll\" back towarads the local minimum.\\\n",
    "If the learning is to high though, the model may keep stepping over the local minimum, never finding it.\\\n",
    "\\\n",
    "If the learning rate is set lower, the increments that weights are adjusted will be smaller.\\\n",
    "The model will reach the local minimum, but it may take a lot longer to get there, slowing down the training.\\\n",
    "Another thing to consider when developing strategies in the future is if this is the truly the global minimum.\\\n",
    "For instance, lets look at another cost/$\\hat{y}$ chart.\\\n",
    "\\\n",
    "![two_min](./img/grad_desc(4).png)\n",
    "\\\n",
    "If the learning rate is set to low the model might find what it thinks is the best minimum, when it can actually do better.\\\n",
    "There will be more stategies on handeling this in another section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Types Of Gradient Descent\n",
    "There three main types of gradient decent.\\\n",
    "This section will go over them at a high level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Gradient Descent\n",
    "Also called \"Vanilla\" gradient descent, will calculate the error for every observation in the dataset.\\\n",
    "Only after **all** the observations in the dataset have been evaluated, will the models parameters be updated.\\\n",
    "Batch gradient descent is computationally efficient, and produces a stable gradient with stable convergence.\\\n",
    "The stable gradient however, may converge before the best model can be acheived.\\\n",
    "this method also requires the entire dataset be store in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "Stochastic gradient descent, unlike batch gradient descent, will update the model after evaluating every observation.\\\n",
    "Stochastic gradient descent can also be a tool for finding the true global minimum when batch gradient decent fails to find it.\\\n",
    "This can be computationally expensive, but depending on the problem, it can be faster than batch gradient descent.\\\n",
    "Also the frequency of updates may result in noisy gradients, which may cause a sparatic error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch Gradient Descent\n",
    "Mini-batch gradient descent is like a happy medium of the two.\\\n",
    "With mini-batch gradient descent, the dataset is broken into small batches and the model is updated after ever mini-batch.\\\n",
    "This way we can have the computational effiecency, stable gradients, and a healthy balacnce of update frequency.\\\n",
    "A common mini-batch size would be 50-256, but like other machine learning techniques, there is no real clear rule."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

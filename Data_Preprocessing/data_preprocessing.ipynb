{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for converting or minipulating the data\n",
    "import matplotlib.pyplot as plt # for plotting the data on graph to see\n",
    "import pandas as pd # for importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more tools that we will use as we advance.\\\n",
    "These are the basic tools for now so we can focus more understanding what we are doing and why.\\\n",
    "In fact there are libraries that we will use to help in the preprocessing stage.\\\n",
    "More on that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset\n",
    "Here we imported that Data.csv and stored it in Variable called dataset.\\\n",
    "What csv_read returns is called a dataframe.\\\n",
    "A Dataframe is a 2 dimensional data structure, like a 2 dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any dataset, that you will train a model with, you will have two disticnt entities.\\\n",
    "The set a features, which are the known characteristics of the observation.\\\n",
    "Or the independent variable(s).\\\n",
    "Then the set of dependent variable.\\\n",
    "\\\n",
    "Lets take a look at our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here 4 colums, location, age, income, and if the bought a product.\\\n",
    "Real quick we can make out that if a person purchased a product is less likey to affect the other three columns.\\\n",
    "While any of the other may affect if someone does buy that product.\\\n",
    "We can safely say that (Country, Age, Salary) are the features and (Purchased) is the independent variable.\\\n",
    "We also have two cells with missing data.  More on that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE .values turns the dataframe to a numpy array\n",
    "x = dataset.iloc[:,:-1].values # All Rows, All Columns except the last / feature set / independent variables\n",
    "y = dataset.iloc[:,-1].values # All Rows, Only last column / output vecter / dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already mentioned, dataset is a pandas dataframe that represents a tabel of data.\\\n",
    "Its not an array, but for now lets think of it as an array of arrays.\\\n",
    "We know in Python we index in a range like so: arr[ start : end : step ]\\\n",
    "We also know [ -1 ] is the same as indexing the last element.\\\n",
    "Well, what we might not know is that we can't index a dataframe like an array: dataset[ : ][ : -1 ]\\\n",
    "The Pandas dataframe frame has a built in method for indexing data called iloc.\\\n",
    "Pandas.iloc[  ] requires 1 argument but can take 2. indexing of the first dimension and then the second.\\\n",
    "Indexing values can bet both a range or a single index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Data\n",
    "So as we seen above there was some data missing in our dataset.\\\n",
    "There a couple of ways to handle missing data:\n",
    "- First if the dataset is very large and we are only missing a small %, we can just delete rows with missing data.\n",
    "- A second way, and the way we'll do it is, replace the data with the avg of all the rows in that column of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are add to out Data Preprocessing Tools.\\\n",
    "Normally we would import this with the rest of the imports at the top of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we imported SimpleImputer is a class of sklearn library.\\\n",
    "Next we create a variable to store our new class obj and pass in a couple of arguments.\\\n",
    "First is missing_values, by pass np.nan we are basically saying and cell that doesnt have a value, or \"not a number\"\n",
    "\\\n",
    "SimpleImputer also can do more than replace empty vaules with an average.\\\n",
    "You can also do things like the median, or most common value if its categorical like Country.\\\n",
    "\\\n",
    "NOTE: this set up is for numerical values, we will only want to apply it to the age and salary columns.\\\n",
    "For good practice, when doing this include all numerical columns, as we wont really know where there is missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(x[:,1:3])\n",
    "x[:, 1:3] = imputer.transform(x[:,1:3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see all the cells are full and the two oddballs are very obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Data\n",
    "### Encoding The Independent Variable\n",
    "Looking at our dataset, most of the data is a numerical value which is good.\\\n",
    "Our learning models will tend to have difficulty finding correlation with strings and the output vector.\\\n",
    "Which is why we are going to encode categorical data such as Country.\\\n",
    "You may think that we would just asign countries numerical values,\\\n",
    "but we dont want to give the impression that there is a ordering relation between countries.\\\n",
    "In other words Franch isn't first, Spain isn't second and so on.\\\n",
    "\\\n",
    "The Solution is \"one hot encoding\".\\\n",
    "This is were instead of giving a numerical value to cells with \"Germany\" we give a 1D vecter.\\\n",
    "So instead of it being:\n",
    "- France = 0\n",
    "- Spain = 1\n",
    "- Germany = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it would be:\n",
    "- France = [1,0,0]\n",
    "- Spain = [0,1,0]\n",
    "- Germany = [0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#                                say 2 encode, Encode Class, What Cols  // passthrough says to leave unencoded cols, default is to drop\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "x = np.array(ct.fit_transform(x)) # fit_transform returns a new matrix were all the countries are encoded, but is not a np array\n",
    "# its easily converted us np.array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Encoding The Dependent Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data Into Train/Test Sets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
